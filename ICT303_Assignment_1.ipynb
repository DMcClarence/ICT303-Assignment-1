{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Install Required Packages"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cu126\n",
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install tensorboard\n",
    "%pip install scikit-learn\n",
    "%pip install seaborn"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fix Tensorboard Ghost Processes\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "shutil.rmtree(os.path.join(tempfile.gettempdir(), '.tensorboard-info'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sErBd01nhySo",
    "outputId": "f5a9c55a-e98a-4bbe-c9ab-9787e7a7d898"
   },
   "cell_type": "code",
   "source": [
    "# Set Up\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from DataLoader import DataLoader\n",
    "from MLP import MLP\n",
    "from VGG16 import VGG16\n",
    "from PreTrainedVGG16 import PreTrainedVGG16\n",
    "from Trainer import Trainer\n",
    "\n",
    "def img_show(img):\n",
    "    img = img / 2 + 0.5 # unnormalize\n",
    "    np_img = img.cpu().numpy()\n",
    "    plt.imshow(np.transpose(np_img, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "display_labels = [\"accessories\", \"jackets\", \"jeans\", \"knitwear\", \"shirts\", \"shoes\", \"shorts\", \"tees\"]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Setup MLP model for Training"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pjZbfGugN648",
    "outputId": "cc95bd9c-7122-4f80-ec45-386462010c08"
   },
   "cell_type": "code",
   "source": [
    "# Train Model\n",
    "%load_ext tensorboard\n",
    "train_set = DataLoader(data_dir=os.getcwd(), trans_width=124, trans_height=124).load(dataset=\"/data/train\", batch_size=32, shuffle=True, workers=2)\n",
    "valid_loader = DataLoader(data_dir=os.getcwd(), trans_width=124, trans_height=124).load(dataset=\"/data/valid\", batch_size=10, shuffle=False, workers=2)\n",
    "mlp_model = MLP(log_dir=os.getcwd()+\"/MLP\", lr=1e-04).to(device)\n",
    "mlp_trainer = Trainer(log_dir=os.getcwd(), n_epochs=6, device=device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train MLP Model"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5UC0EQcIl7im",
    "outputId": "c8b58948-575b-4dfa-a709-3b68758b6564"
   },
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "mlp_trainer.fit(mlp_model, train_set, valid_loader)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "2CO3MAWwwQH_",
    "outputId": "ec0fa5f9-da41-4629-dab8-e60217ba9011"
   },
   "cell_type": "code",
   "source": [
    "plt.clf()\n",
    "plt.plot(getattr(mlp_trainer, \"avg_train_loss\"), label=\"Avg. Training Loss\")\n",
    "plt.plot(getattr(mlp_trainer, \"avg_valid_loss\"), label=\"Avg. Validation Loss\")\n",
    "plt.plot(getattr(mlp_trainer, \"training_accuracy\"), label=\"Training Accuracy (x100)%\")\n",
    "plt.plot(getattr(mlp_trainer, \"validation_accuracy\"), label=\"Validation Accuracy (x100)%\")\n",
    "plt.legend()\n",
    "plt.savefig(os.getcwd() + \"/MLP/MLP_Loss_Plot.jpg\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Write MLP Loss to Tensorboard"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jshoHgl2XJdZ",
    "outputId": "7fe49956-df3e-4386-d1d6-6b9a76f1b411"
   },
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "for epoch in range(len(mlp_trainer.avg_train_loss)):\n",
    "    mlp_model.writer.add_scalars('MLP', {'Avg_Training_Loss': mlp_trainer.avg_train_loss[epoch],\n",
    "                                         'Avg_Validation_Loss': mlp_trainer.avg_valid_loss[epoch],\n",
    "                                         'Training_Accuracy(x100)%': mlp_trainer.training_accuracy[epoch],\n",
    "                                         'Validation_Accuracy(x100)%': mlp_trainer.validation_accuracy[epoch]}, epoch)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "e-FZ20U0PzWj"
   },
   "source": "mlp_model.writer.close()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%tensorboard --logdir=./MLP",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Test MLP Model"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "bxV-URGvqmrw",
    "outputId": "6e4c68a9-b5d6-4a4d-c463-daf3b72db6bc"
   },
   "source": [
    "test_loader = DataLoader(data_dir=os.getcwd(), trans_width=124, trans_height=124).load(dataset=\"/data/test\", batch_size=10, shuffle=False, workers=2)\n",
    "classes = train_set.dataset.classes\n",
    "test_ground_truth = [4, 4, 2, 2, 7, 3, 5]\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "images = images.to(device)\n",
    "\n",
    "img_show(torchvision.utils.make_grid(images))\n",
    "mlp_model.eval()\n",
    "output = mlp_model(images).to(device)\n",
    "estimatedLabels = torch.max(output, 1).indices\n",
    "\n",
    "print('Estimated Labels: ', ' '.join(f'{classes[estimatedLabels[j]]:5s}' for j in range(images.shape[0])))\n",
    "\n",
    "print(estimatedLabels, test_ground_truth)\n",
    "\n",
    "cm = confusion_matrix(y_pred=estimatedLabels.cpu(), y_true=test_ground_truth, labels=display_labels)\n",
    "dcm = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
    "dcm.plot()\n",
    "plt.show()\n",
    "plt.savefig(os.getcwd() + \"/MLP/MLP_Confusion_Matrix.jpg\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KpMN7F2hp6By"
   },
   "source": [
    "# resume = False\n",
    "# if resume:\n",
    "#   epochs = model.load(dir=\"Mydrive/ICT303_Results/MLP/MLP_Epoch_11.tar\")\n",
    "#   trainer.load(dir=f\"Mydrive/ICT303_Results/MLP/MLP_Epoch_{epochs}_TrainLoss.tar\")\n",
    "#   # validator.load(dir=f\"Mydrive/ICT303_Results/MLP/MLP_Epoch_{epochs}_ValLoss.tar\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Setup VGG16 Model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train VGG16 Model\n",
    "%load_ext tensorboard\n",
    "train_loader = DataLoader(data_dir=os.getcwd(), trans_width=224, trans_height=224).load(dataset=\"/data/train\", batch_size=32, shuffle=True, workers=2)\n",
    "valid_loader = DataLoader(data_dir=os.getcwd(), trans_width=224, trans_height=224).load(dataset=\"/data/valid\", batch_size=10, shuffle=False, workers=2)\n",
    "vgg16_model = VGG16(log_dir=os.getcwd()+\"/VGG16\", output_size=8, lr=1e-4).to(device)\n",
    "vgg16_trainer = Trainer(log_dir=os.getcwd()+\"/VGG16\", n_epochs=10, device=device, use_lr_scheduler=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BNcrKdaasd_E",
    "outputId": "1891e5d6-a854-4b67-9961-a9bc66d9a72d"
   },
   "source": [
    "%load_ext tensorboard\n",
    "vgg16_trainer.fit(vgg16_model, train_loader, valid_loader)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "Na9Cs01Bsg9U",
    "outputId": "90fcd481-e4ed-4f6d-b2d8-9fdd1c70dbfb"
   },
   "source": [
    "plt.clf()\n",
    "plt.plot(getattr(vgg16_trainer, \"avg_train_loss\"), label=\"Avg. Training Loss\")\n",
    "plt.plot(getattr(vgg16_trainer, \"avg_valid_loss\"), label=\"Avg. Validation Loss\")\n",
    "plt.plot(getattr(vgg16_trainer, \"training_accuracy\"), label=\"Training Accuracy (x100)%\")\n",
    "plt.plot(getattr(vgg16_trainer, \"validation_accuracy\"), label=\"Validation Accuracy (x100)%\")\n",
    "plt.legend()\n",
    "plt.savefig(os.getcwd() + \"/VGG16/VGG16_Loss_Plot.jpg\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "for epoch in range(len(vgg16_trainer.avg_train_loss)):\n",
    "    vgg16_model.writer.add_scalars('VGG16', {'Avg_Training_Loss': vgg16_trainer.avg_train_loss[epoch],\n",
    "                                             'Avg_Validation_Loss': vgg16_trainer.avg_valid_loss[epoch],\n",
    "                                             'Training_Accuracy(x100)%': vgg16_trainer.training_accuracy[epoch],\n",
    "                                             'Validation_Accuracy(x100)%': vgg16_trainer.validation_accuracy[epoch]}, epoch)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "vgg16_model.writer.close()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%tensorboard --logdir=./VGG16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_loader = DataLoader(data_dir=os.getcwd(), trans_width=224, trans_height=224).load(dataset=\"/data/test\", batch_size=10, shuffle=False, workers=2)\n",
    "classes = train_loader.dataset.classes\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "images = images.to(device)\n",
    "\n",
    "img_show(torchvision.utils.make_grid(images))\n",
    "vgg16_model.eval()\n",
    "output = vgg16_model(images).to(device)\n",
    "estimatedLabels = torch.max(output, 1).indices\n",
    "\n",
    "print('Estimated Labels: ', ' '.join(f'{classes[estimatedLabels[j]]:5s}' for j in range(images.shape[0])))\n",
    "\n",
    "cm = confusion_matrix(estimatedLabels.cpu(), test_ground_truth)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=range(8), yticklabels=range(8))\n",
    "plt.ylabel(\"Ground Truth\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "plt.savefig(os.getcwd() + \"/VGG16/VGG16_Confusion_Matrix.jpg\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Setup PreTrained VGG16 Model for Training (Just last layer of classifier)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "train_set = DataLoader(data_dir=os.getcwd(), trans_width=224, trans_height=224).load(dataset=\"/data/train\", batch_size=32, shuffle=True, workers=2)\n",
    "valid_loader = DataLoader(data_dir=os.getcwd(), trans_width=224, trans_height=224).load(dataset=\"/data/valid\", batch_size=10, shuffle=False, workers=2)\n",
    "torch_vgg16_model = PreTrainedVGG16(log_dir=os.getcwd()+\"/PreTrainedVGG16\", lr=0.001).to(device)\n",
    "torch_vgg16_trainer = Trainer(log_dir=os.getcwd(), n_epochs=3, device=device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train PreTrained VGG16 Model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "torch_vgg16_trainer.fit(torch_vgg16_model, train_set, valid_loader)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.clf()\n",
    "plt.plot(getattr(torch_vgg16_trainer, \"avg_train_loss\"), label=\"Avg. Training Loss\")\n",
    "plt.plot(getattr(torch_vgg16_trainer, \"avg_valid_loss\"), label=\"Avg. Validation Loss\")\n",
    "plt.plot(getattr(torch_vgg16_trainer, \"training_accuracy\"), label=\"Training Accuracy (%)\")\n",
    "plt.plot(getattr(torch_vgg16_trainer, \"validation_accuracy\"), label=\"Validation Accuracy (%)\")\n",
    "plt.legend()\n",
    "plt.savefig(os.getcwd() + \"/VGG16/VGG16_Loss_Plot.jpg\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Test PreTrained VGG16 Model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "for epoch in range(len(torch_vgg16_trainer.avg_train_loss)):\n",
    "    torch_vgg16_model.writer.add_scalars('PreTrainedVGG16', {'Avg_Training_Loss': torch_vgg16_trainer.avg_train_loss[epoch],\n",
    "                                                             'Avg_Validation_Loss': torch_vgg16_trainer.avg_valid_loss[epoch],\n",
    "                                                             'Training_Accuracy(x100)%': torch_vgg16_trainer.training_accuracy[epoch],\n",
    "                                                             'Validation_Accuracy(x100)%': torch_vgg16_trainer.validation_accuracy[epoch]}, epoch)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch_vgg16_model.writer.close()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%tensorboard --logdir=./PreTrainedVGG16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_loader = DataLoader(data_dir=os.getcwd(), trans_width=224, trans_height=224).load(dataset=\"/data/test\", batch_size=10, shuffle=False, workers=2)\n",
    "classes = train_set.dataset.classes\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "images = images.to(device)\n",
    "\n",
    "img_show(torchvision.utils.make_grid(images))\n",
    "torch_vgg16_model.eval()\n",
    "output = torch_vgg16_model(images).to(device)\n",
    "estimatedLabels = torch.max(output, 1).indices\n",
    "\n",
    "print('Estimated Labels: ', ' '.join(f'{classes[estimatedLabels[j]]:5s}' for j in range(images.shape[0])))\n",
    "\n",
    "cm = confusion_matrix(estimatedLabels.cpu(), test_ground_truth)\n",
    "print(estimatedLabels, test_ground_truth)\n",
    "sns.heatmap(cm, annot=True, xticklabels=range(8), yticklabels=range(8))\n",
    "plt.ylabel(\"Ground Truth\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "plt.savefig(os.getcwd() + \"/PreTrainedVGG16/PreTrainedVGG16_Confusion_Matrix.jpg\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
