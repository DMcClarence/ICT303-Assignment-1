{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Install Required Packages"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cu129\n",
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install tensorboard\n",
    "%pip install scikit-learn\n",
    "%pip install seaborn"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fix Tensorboard Ghost Processes\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "shutil.rmtree(os.path.join(tempfile.gettempdir(), '.tensorboard-info'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sErBd01nhySo",
    "outputId": "f5a9c55a-e98a-4bbe-c9ab-9787e7a7d898",
    "ExecuteTime": {
     "end_time": "2025-09-17T04:43:37.708042Z",
     "start_time": "2025-09-17T04:43:20.141755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set Up\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from DataLoader import DataLoader\n",
    "from MLP import MLP\n",
    "from VGG16 import VGG16\n",
    "from PreTrainedVGG16 import PreTrainedVGG16\n",
    "from Trainer import Trainer\n",
    "\n",
    "def img_show(img):\n",
    "    img = img / 2 + 0.5 # unnormalize\n",
    "    np_img = img.cpu().numpy()\n",
    "    plt.imshow(np.transpose(np_img, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Setup MLP model for Training"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pjZbfGugN648",
    "outputId": "cc95bd9c-7122-4f80-ec45-386462010c08"
   },
   "cell_type": "code",
   "source": [
    "# Train Model\n",
    "%load_ext tensorboard\n",
    "train_set = DataLoader(data_dir=os.getcwd(), trans_width=224, trans_height=224).load(dataset=\"/data/train\", batch_size=32, shuffle=True, workers=2)\n",
    "valid_loader = DataLoader(data_dir=os.getcwd(), trans_width=224, trans_height=224).load(dataset=\"/data/valid\", batch_size=32, shuffle=False, workers=2)\n",
    "mlp_model = MLP(log_dir=os.getcwd()+\"/MLP\", lr=1e-04).to(device)\n",
    "mlp_trainer = Trainer(log_dir=os.getcwd()+\"/MLP\", n_epochs=3, device=device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train MLP Model"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5UC0EQcIl7im",
    "outputId": "c8b58948-575b-4dfa-a709-3b68758b6564"
   },
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "mlp_trainer.fit(model=mlp_model, train=train_set, valid=valid_loader, use_lr_scheduler=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "2CO3MAWwwQH_",
    "outputId": "ec0fa5f9-da41-4629-dab8-e60217ba9011"
   },
   "cell_type": "code",
   "source": [
    "plt.clf()\n",
    "plt.plot(getattr(mlp_trainer, \"avg_train_loss\"), label=\"Avg. Training Loss\")\n",
    "plt.plot(getattr(mlp_trainer, \"avg_valid_loss\"), label=\"Avg. Validation Loss\")\n",
    "plt.plot(getattr(mlp_trainer, \"training_accuracy\"), label=\"Training Accuracy (x100)%\")\n",
    "plt.plot(getattr(mlp_trainer, \"validation_accuracy\"), label=\"Validation Accuracy (x100)%\")\n",
    "plt.legend()\n",
    "plt.savefig(os.getcwd() + \"/MLP/MLP_Loss_Plot.jpg\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Write MLP Loss to Tensorboard"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jshoHgl2XJdZ",
    "outputId": "7fe49956-df3e-4386-d1d6-6b9a76f1b411"
   },
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "for epoch in range(len(mlp_trainer.avg_train_loss)):\n",
    "    mlp_model.writer.add_scalars('MLP', {'Avg_Training_Loss': mlp_trainer.avg_train_loss[epoch],\n",
    "                                         'Avg_Validation_Loss': mlp_trainer.avg_valid_loss[epoch],\n",
    "                                         'Training_Accuracy(x100)%': mlp_trainer.training_accuracy[epoch],\n",
    "                                         'Validation_Accuracy(x100)%': mlp_trainer.validation_accuracy[epoch]}, epoch)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "e-FZ20U0PzWj"
   },
   "source": "mlp_model.writer.close()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%tensorboard --logdir=./MLP",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Test MLP Model"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "bxV-URGvqmrw",
    "outputId": "6e4c68a9-b5d6-4a4d-c463-daf3b72db6bc"
   },
   "source": [
    "test_loader = DataLoader(data_dir=os.getcwd(), trans_width=124, trans_height=124).load(dataset=\"/data/test\", batch_size=32, shuffle=False, workers=2)\n",
    "classes = train_set.dataset.classes\n",
    "test_ground_truth = [4, 4, 2, 2, 7, 3, 5]\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "images = images.to(device)\n",
    "\n",
    "img_show(torchvision.utils.make_grid(images))\n",
    "mlp_model.eval()\n",
    "output = mlp_model(images).to(device)\n",
    "estimatedLabels = torch.max(output, 1).indices\n",
    "\n",
    "print('Estimated Labels: ', ' '.join(f'{classes[estimatedLabels[j]]:5s}' for j in range(images.shape[0])))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KpMN7F2hp6By"
   },
   "source": [
    "# resume = False\n",
    "# if resume:\n",
    "#   epochs = mlp_model.load(dir=\"MLP/MLP_Epoch_11.tar\")\n",
    "#   trainer.load(dir=f\"MLP/Epoch_{epochs}_LossAccuracy.tar\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Setup VGG16 Model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train VGG16 Model\n",
    "%load_ext tensorboard\n",
    "train_loader = DataLoader(data_dir=os.getcwd(), trans_width=224, trans_height=224).load(dataset=\"/data/train\", batch_size=32, shuffle=True, workers=2)\n",
    "valid_loader = DataLoader(data_dir=os.getcwd(), trans_width=224, trans_height=224).load(dataset=\"/data/valid\", batch_size=32, shuffle=False, workers=2)\n",
    "vgg16_model = VGG16(log_dir=os.getcwd()+\"/VGG16\", output_size=8, lr=1e-4).to(device)\n",
    "vgg16_trainer = Trainer(log_dir=os.getcwd()+\"/VGG16\", n_epochs=3, device=device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BNcrKdaasd_E",
    "outputId": "1891e5d6-a854-4b67-9961-a9bc66d9a72d"
   },
   "source": [
    "%load_ext tensorboard\n",
    "vgg16_trainer.fit(model=vgg16_model, train=train_loader, valid=valid_loader, use_lr_scheduler=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "Na9Cs01Bsg9U",
    "outputId": "90fcd481-e4ed-4f6d-b2d8-9fdd1c70dbfb"
   },
   "source": [
    "plt.clf()\n",
    "plt.plot(getattr(vgg16_trainer, \"avg_train_loss\"), label=\"Avg. Training Loss\")\n",
    "plt.plot(getattr(vgg16_trainer, \"avg_valid_loss\"), label=\"Avg. Validation Loss\")\n",
    "plt.plot(getattr(vgg16_trainer, \"training_accuracy\"), label=\"Training Accuracy (x100)%\")\n",
    "plt.plot(getattr(vgg16_trainer, \"validation_accuracy\"), label=\"Validation Accuracy (x100)%\")\n",
    "plt.legend()\n",
    "plt.savefig(os.getcwd() + \"/VGG16/VGG16_Loss_Plot.jpg\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "for epoch in range(len(vgg16_trainer.avg_train_loss)):\n",
    "    vgg16_model.writer.add_scalars('VGG16', {'Avg_Training_Loss': vgg16_trainer.avg_train_loss[epoch],\n",
    "                                             'Avg_Validation_Loss': vgg16_trainer.avg_valid_loss[epoch],\n",
    "                                             'Training_Accuracy(x100)%': vgg16_trainer.training_accuracy[epoch],\n",
    "                                             'Validation_Accuracy(x100)%': vgg16_trainer.validation_accuracy[epoch]}, epoch)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "vgg16_model.writer.close()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%tensorboard --logdir=./VGG16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_loader = DataLoader(data_dir=os.getcwd(), trans_width=224, trans_height=224).load(dataset=\"/data/test\", batch_size=32, shuffle=False, workers=2)\n",
    "classes = train_loader.dataset.classes\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "images = images.to(device)\n",
    "\n",
    "img_show(torchvision.utils.make_grid(images))\n",
    "vgg16_model.eval()\n",
    "output = vgg16_model(images).to(device)\n",
    "estimatedLabels = torch.max(output, 1).indices\n",
    "\n",
    "print('Estimated Labels: ', ' '.join(f'{classes[estimatedLabels[j]]:5s}' for j in range(images.shape[0])))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Setup PreTrained VGG16 Model for Training (Just last layer of classifier)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "train_set = DataLoader(data_dir=os.getcwd(), trans_width=224, trans_height=224).load(dataset=\"/data/train\", batch_size=32, shuffle=True, workers=2)\n",
    "valid_loader = DataLoader(data_dir=os.getcwd(), trans_width=224, trans_height=224).load(dataset=\"/data/valid\", batch_size=32, shuffle=False, workers=2)\n",
    "torch_vgg16_model = PreTrainedVGG16(log_dir=os.getcwd()+\"/PreTrainedVGG16\", lr=1e-4).to(device)\n",
    "torch_vgg16_trainer = Trainer(log_dir=os.getcwd()+\"/PreTrainedVGG16\", n_epochs=3, device=device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train PreTrained VGG16 Model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "torch_vgg16_trainer.fit(model=torch_vgg16_model, train=train_set, valid=valid_loader, use_lr_scheduler=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.clf()\n",
    "plt.plot(getattr(torch_vgg16_trainer, \"avg_train_loss\"), label=\"Avg. Training Loss\")\n",
    "plt.plot(getattr(torch_vgg16_trainer, \"avg_valid_loss\"), label=\"Avg. Validation Loss\")\n",
    "plt.plot(getattr(torch_vgg16_trainer, \"training_accuracy\"), label=\"Training Accuracy (%)\")\n",
    "plt.plot(getattr(torch_vgg16_trainer, \"validation_accuracy\"), label=\"Validation Accuracy (%)\")\n",
    "plt.legend()\n",
    "plt.savefig(os.getcwd() + \"/VGG16/VGG16_Loss_Plot.jpg\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Test PreTrained VGG16 Model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "for epoch in range(len(torch_vgg16_trainer.avg_train_loss)):\n",
    "    torch_vgg16_model.writer.add_scalars('PreTrainedVGG16', {'Avg_Training_Loss': torch_vgg16_trainer.avg_train_loss[epoch],\n",
    "                                                             'Avg_Validation_Loss': torch_vgg16_trainer.avg_valid_loss[epoch],\n",
    "                                                             'Training_Accuracy(x100)%': torch_vgg16_trainer.training_accuracy[epoch],\n",
    "                                                             'Validation_Accuracy(x100)%': torch_vgg16_trainer.validation_accuracy[epoch]}, epoch)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch_vgg16_model.writer.close()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%tensorboard --logdir=./PreTrainedVGG16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_loader = DataLoader(data_dir=os.getcwd(), trans_width=224, trans_height=224).load(dataset=\"/data/test\", batch_size=32, shuffle=False, workers=2)\n",
    "classes = train_set.dataset.classes\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "images = images.to(device)\n",
    "\n",
    "img_show(torchvision.utils.make_grid(images))\n",
    "torch_vgg16_model.eval()\n",
    "output = torch_vgg16_model(images).to(device)\n",
    "estimatedLabels = torch.max(output, 1).indices\n",
    "\n",
    "print('Estimated Labels: ', ' '.join(f'{classes[estimatedLabels[j]]:5s}' for j in range(images.shape[0])))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Before I started tuning the models, I spent majority of the time implementing the foundations of each model, the trainer, dataloader and confusion matrices."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To implement the trainer, I adapted the trainer from my lab work. I made modifications to allow me to calculate both generalization loss and training loss during the training phase, and added a learning rate scheduler as it is usually highly recommended. I decided to use an exponential learning rate scheduler as it was simple to implement. I also added the necessary code to save the required data at regular checkpoints."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I also then created a function that I could use to plot and save a confusion matrix. Once I had that, I added the required code to the Trainer. This is done during the validation of the last epoch during training to get an idea of how well the model is classifying each class. I do it then as the test set does not have at least a single instance of every class. The downside to this is that at this point it may be memorizing the validation set, however using the graphs of generalization/training loss and accuracy, I can retrain to the point where it typically starts to converge, meaning the confusion matrix should give a good idea of the model performance. Once I had all this in place, I began to implement basic architecture of each model."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To implement the MLP model, I adapted my lab work as it was proven there to work well for image classification. I also added some dropout between each layer to prevent over-relying on specific neurons during training. I just used a learning rate of 1x10^-4, batch size of 32 and 3 epochs for testing to make sure the MLP and all my components were working correctly. This process went smoothly."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "I then began to implement the VGG16 architecture from the 2015 research paper by Simonyan and Zisserman (https://arxiv.org/pdf/1409.1556). This is where progress was halted and majority of my time was spent. I followed the architecture outlined in the paper but was getting some really strange results when I started testing it. I initially started with the same hyper parameters as the MLP, but at the completion of my testing, I noticed the lines for training and validation were practically flat and I knew I had a problem. I first tried adjusting the number of epochs to 25 as I thought maybe the issue was just that I didn't train it for long enough to give it time to learn, due to how deep the architecture is, but I still had flat lines. So I tried increasing the learning rate because I thought maybe it was too low for it to learn anything. I increased it from 1x10^-4, to 1x10^-3, which still gave me the same result. So I continued increasing it one by one until I had a learning rate of 1 in which resulted in the loss reading as NaN. I also tried some learning rates smaller than 1x10^-4 just out of curiosity to see if I was missing something, but still no change from the flat lines. Next I tried playing with the batch sizes. I tried some smaller batch sizes in the hopes that it would pick up more on the features on the image and learn something, but again flat lines on the graph. I also tried some larger ones but alas no changed.\n",
    "\n",
    "![Alt Text](vgg16_issue.png)\n",
    "\n",
    "The only thing I could think of at this point was that maybe the dataset was too small, so I tried testing it on the CIRFAR10 dataset from torchvision to try and narrow down the issue. I tried training it on this dataset for 25 epochs with a learning rate starting at 1x10^-4. My graph still appeared the same, so I had no clue what could be wrong. I tried everything I could think of. Finally, I decided to examine the architecture I had implemented against the research paper again. Everything seemed fine, but I noticed that the architecture called for a softmax activation at the very end which I implemented and thought I would try without it. The model began to train as expected. So I dove deeeper to try and find out why this was the case, because I knew the architecture required it, but for some reason didn't work when I included it. I found that Pytorch's CrossEntropyLoss function already internally applies a softmax activation, therefore the two were conflicting and the model wasn't able to learn correctly."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, I implemented the PreTrained VGG16 model from Pytorch. I initialised the weights using one of the variables from Pytorch for this model to minimise the need for training as much as possible. I redefined the last layer of the model to output the correct number of classes, and to be able to train it for this specific set of classes. I checked it using the same initial hyper parameters as the previous models and everything was in place to begin training each model. However, time at this point was running out."
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
